2024-06-30 19:38:50,446 - INFO - Trial 0: learning_rate=0.01349015891538444, batch_size=32, num_layers=5, dropout_prob=0.8340946000785591, accuracy=0.8525214000510501
2024-06-30 19:41:47,459 - INFO - Trial 1: learning_rate=0.0018143791973666197, batch_size=64, num_layers=3, dropout_prob=0.17704772331350183, accuracy=0.8794056415001459
2024-06-30 19:44:38,557 - INFO - Trial 2: learning_rate=0.03793439555151653, batch_size=32, num_layers=1, dropout_prob=0.5834601686759624, accuracy=0.8557126057467911
2024-06-30 19:47:18,715 - INFO - Trial 3: learning_rate=0.08602817383930032, batch_size=32, num_layers=2, dropout_prob=0.08063569494418388, accuracy=0.8525214000510501
2024-06-30 19:50:18,046 - INFO - Trial 4: learning_rate=0.0030374082741458043, batch_size=16, num_layers=2, dropout_prob=0.8180871160554318, accuracy=0.8536389772644399
2024-06-30 19:53:04,379 - INFO - Trial 5: learning_rate=7.954699624003445e-05, batch_size=64, num_layers=2, dropout_prob=0.33036995915236733, accuracy=0.8524735405119603
2024-06-30 19:56:14,238 - INFO - Trial 6: learning_rate=4.8129174411669636e-05, batch_size=32, num_layers=4, dropout_prob=0.0914859165643448, accuracy=0.8617913369676196
2024-06-30 19:59:17,340 - INFO - Trial 7: learning_rate=0.005995856156940027, batch_size=64, num_layers=4, dropout_prob=0.630888149587158, accuracy=0.854438060640315
2024-06-30 20:02:04,565 - INFO - Trial 8: learning_rate=9.715769321107496e-05, batch_size=32, num_layers=2, dropout_prob=0.43159027108824, accuracy=0.8532868677982789
2024-06-30 20:05:12,639 - INFO - Trial 9: learning_rate=0.003865948362385399, batch_size=32, num_layers=4, dropout_prob=0.47313222567870783, accuracy=0.8542508956570887
2024-06-30 20:08:01,491 - INFO - Trial 10: learning_rate=0.0003883162805291103, batch_size=64, num_layers=3, dropout_prob=0.2645402894894989, accuracy=0.8671342277749416
2024-06-30 20:10:51,400 - INFO - Trial 11: learning_rate=0.0005164088936113769, batch_size=64, num_layers=3, dropout_prob=0.25040153145320454, accuracy=0.8718885602027421
2024-06-30 20:13:42,110 - INFO - Trial 12: learning_rate=0.0006052237648623988, batch_size=64, num_layers=3, dropout_prob=0.21510851266405406, accuracy=0.8746094319756418
2024-06-30 20:16:18,455 - INFO - Trial 13: learning_rate=1.0353479372799057e-05, batch_size=64, num_layers=3, dropout_prob=0.03934672184710164, accuracy=0.8525214000510501
2024-06-30 20:20:12,085 - INFO - Trial 14: learning_rate=0.0012421834912060038, batch_size=16, num_layers=5, dropout_prob=0.1883485596995974, accuracy=0.8889368117342473
2024-06-30 20:24:04,931 - INFO - Trial 15: learning_rate=0.0020932434303297205, batch_size=16, num_layers=5, dropout_prob=0.16390048262318072, accuracy=0.8792159126130397
2024-06-30 20:27:43,151 - INFO - Trial 16: learning_rate=0.014445164335284671, batch_size=16, num_layers=5, dropout_prob=0.38777259603983866, accuracy=0.8525214000510501
2024-06-30 20:30:54,546 - INFO - Trial 17: learning_rate=0.001441924996255431, batch_size=16, num_layers=4, dropout_prob=0.6707669246793104, accuracy=0.8546893232205367
2024-06-30 20:33:45,235 - INFO - Trial 18: learning_rate=0.00023765807968689716, batch_size=16, num_layers=1, dropout_prob=0.945308664714529, accuracy=0.8545955982898191
2024-06-30 20:37:00,922 - INFO - Trial 19: learning_rate=0.0012216259971125482, batch_size=16, num_layers=4, dropout_prob=0.15232586629628453, accuracy=0.886288868782818
